# Deadline Timeline 
Note: Deadlines are at 10am on the day listed

* 3/21/16 Project out
* 4/4/16 Project Proposal DUE (email to nad@umd.edu)
* 4/18/16 Project Progress Report Presentation DUE (in class presentation)
* 5/2/16 Final Project Presentation DUE (in class presentation with guest evaluators)
* 5/13/16 Final Project Report DUE (email to nad@umd.edu)

# Project Description
Your final project should show how you have integrated the knowledge you acquire in this class and are able to apply it to an algorithmic accountability investigation in the interest of finding a news story. The outcome of the project should be a set of code, analysis, and other research that leads to a written piece of publication-quality journalism. You’ll do this project with a partner which will be assigned (details below). 

The context of the project relates to investigating search engine autosuggestions. Autosuggestions are important since they bias online search attention by making it more likely for people to search for some things instead of other things. They could also lead to unintended consequences like defamation, for instance. For a few ideas relating to investigations of autosuggestions see [here](http://www.slate.com/articles/technology/future_tense/2013/08/words_banned_from_bing_and_google_s_autocomplete_algorithms.html) and [here](http://towcenter.org/algorithmic-defamation-the-case-of-the-shameless-autocomplete/). You may be interested in familiarizing yourself with [other research](http://www.tandfonline.com/doi/abs/10.1080/17405904.2012.744320) on the social consequences of autosuggestions. For a broader context of algorithmic accountability reporting, see the Tow Center Report, [Algorithmic Accountability Reporting: On the Investigation of Black Boxes](http://www.nickdiakopoulos.com/wp-content/uploads/2011/07/Algorithmic-Accountability-Reporting_final.pdf), which has many ideas for approaching such an investigation. 

Your first task will be to brainstorm some angles to take on this subject. Think about why autosuggestions might be important to different stakeholders: politicians, celebrities, teachers, law enforcement agents, or almost any other group. Some consequence to consider: accuracy, bias of attention, laws / social norm violations, censorship. Could autosuggestions have negative implications for an individual or group? If different groups or categories of people search for the same thing in different ways how might that shape what is suggested to them? Do people in different parts of the world or in different languages see different autocompletions? And how does any of this compare over time, or across different internet providers like Google and Bing? There are *many* angles you can pursue with this so you're encouraged to think broadly at first and then narrow it down when you feel confident there's something worthy of pursuit. Doing outside research, for instance by reading up on the subject online, may help you narrow your focus. 

Once you decide on a key question or set of questions that you want to investigate you should proceed to collect data to help answer those questions. Here is a .ipynb with a function that can be used to collect autosuggestions from Google and Bing and for different top level domains (e.g. ".com", ".de", ".mx") or languages (e.g. "en", "es"). You can deploy this in many different ways to help you collect data. You'll probably want to come up with a range of queries to test, and depending on your questions you may want to vary the other parameters like top level domain, language, or time (by collected repeatedly at regular intervals). 

After you collect the data to address your chosen questions you'll need to analyze it and make sense of it, ideally finding something newsworthy in the process. You may also consider creating visualizations of the data to help communicate your findings. In the process of data analysis do not forget to synthesis outside research, knowledge, and context in making sense of it. You are expected to "think computationally" in your analysis and use code to help cope with the scale of data analysis. 

Based on your findings you're write two articles: (1) a news article that communicates your findings in a journalistic style, and (2) a methods article to describe your data collection and analysis process. 

**Project Team**   
You will be assigned a partner to work with on the final project. This is done so as to ensure that the team has a balance of journalistic and computing skills. Please contact your partner ASAP to set up a time to meet. Here are the partners with contact information.

**Project Proposal**  
Your project proposal will succinctly describe (~500 words) what you intend to investigate and why it is an interesting and potentially newsworthy endeavor. In order to write an effective proposal you need to convince yourself "there's a there, there" -- that is, there's something [newsworthy](http://www.mediacollege.com/journalism/news/newsworthy.html) to dig into. Thus for the proposal you should have already spent time doing research, collecting preliminary data, and even doing some exploratory analysis of that data. 

In the proposal write-up include information that motivates your investigation: why are you asking the question you're asking about autosuggestions? Also describe the data you have acquired and any additional data you intend to collect. Be sure to describe how you are going to sample it, and what limitations or assumptions you have of the data. Will you be able to answer your investigative question with the data you have? Also be sure to describe what you think the story might be based on your initial explorations. What's the best case outcome? Finally, look ahead and describe any challenges you foresee. 

You should email a PDF of the proposal to nad@umd.edu with a file name of "Final_Project_Proposal_<project_title>.pdf" by the deadline listed above. 

**Project Progress Report Presentation**  
In order to help assess the strengths and weaknesses of your project you will have ~15 minutes (10 minutes of presentation and 5 minutes for questions and feedback) to present your project to the class on the date listed above. This presentation will give you a chance to both receive feedback from other class members as well as to offer your own critiques of their work. You should have made progress implementing your data collection and analysis, and you can use this time to show what you have accomplished thus far, including visualizations or other analyses that are underway. Be sure to explain the intent and motivation of the investigation, the questions you're driving at, the process you're following, and the emerging story. What else do you have left to work on, and is there anything you think you need help with? 

**Final Project Presentation**  
Final project presentations of ~15 minutes will be made in class on the date listed above. This should be the polished version of the progress report presentation you gave previously. Make sure to motivate the project, explain the data you collected and why you collected it the way you did, how you explored it and implemented the analysis with various tools, and what the story is. This will be an open “public” session and other people from the college may be invited to see your projects. For all intents and purposes your project should be done by now. 

**Project Report**  
Your project report is due via email to nad@umd.edu as a PDF with file name “Final_Project_\<project_title\>.pdf” by the date listed above. Firstly, the report should include your investigation written in the style of an article of journalism. It should also include a separate article describing your data collection and analysis methods. Examples of methodology articles are linked to the [first assignment](https://github.com/comp-journalism/UMD-J479V-J779V-Spring2016/blob/master/Asgn1/computational-data-journalism-critique.md). Finally, be sure to reflect on your project and describe what was hard or easy and what you would do differently next time. Don't forget to include a description in some detail of the work that each team member did and how it was broken out. Finally, as part of the submission include a .zip file of your project's code and data (including any data collection scripts or analysis scripts) so that it can be re-run if needed. 
